{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOBko5Pcl4LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd43320-2d3a-448d-9572-71e809cfc7ce"
      },
      "source": [
        "!pip install dask\n",
        "!pip install 'fsspec>=0.3.3'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Collecting fsspec>=0.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 22.4MB/s \n",
            "\u001b[?25hInstalling collected packages: fsspec\n",
            "Successfully installed fsspec-2021.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0WjgT5TcBvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed25c02-739f-4364-c003-096473f3bb28"
      },
      "source": [
        "import os\n",
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "from dask import delayed\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "airports = [\"ATL\", \"CLT\", \"DEN\", \"DFW\", \"EWR\", \"IAH\", \"JFK\", \"LAS\", \"LAX\", \"MCO\", \"MIA\", \"ORD\", \"PHX\", \"SEA\", \"SFO\"]\n",
        "flightCols = [\"Origin\", \"Dest\", \"FlightDate\", \"Quarter\", \"Year\", \"Month\", \"DayofMonth\", \"DepTime\", \"DepDel15\", \"CRSDepTime\", \"DepDelayMinutes\", \"OriginAirportID\", \"DestAirportID\", \"ArrTime\", \"CRSArrTime\", \"ArrDel15\", \"ArrDelayMinutes\"]\n",
        "# \"Date\", \"Airport\"\n",
        "weatherCols = [\"Airport\",\"Year\",\"Month\",\"Day\",\"Hour\",\"WindSpeedKmph\", \"WindDirDegree\", \"WeatherCode\", \"precipMM\", \"Visibility\", \"Pressure\", \"Cloudcover\", \"DewPointF\", \"WindGustKmph\", \"tempF\", \"WindChillF\", \"Humidity\", \"Time\"]\n",
        "weatherKeys = [\"windspeedKmph\", \"winddirDegree\", \"weatherCode\", \"precipMM\", \"visibility\", \"pressure\", \"cloudcover\", \"DewPointF\", \"WindGustKmph\", \"tempF\", \"WindChillF\", \"humidity\", \"time\"]\n",
        "\n",
        "years = ['2016', '2017']\n",
        "\n",
        "months = range(1, 13)\n",
        "days   = range(0,32)\n",
        "hours = range(0,24)\n",
        "\n",
        "def hour(x):\n",
        "    if len(str(x)) > 2:\n",
        "        return int(str(x)[-3::-1][::-1]+\"00\")\n",
        "    # elif len(str(x)) <2:\n",
        "      # return 100\n",
        "    return 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fdf = dd.read_csv(os.path.join('drive','MyDrive','Data','flight-data','*','*','*.csv'),usecols=flightCols)\n",
        "fdf = fdf.compute()\n",
        "fdf= fdf.dropna()\n",
        "fdf = fdf[fdf['Origin'].isin(airports)]\n",
        "fdf = fdf[fdf['Dest'].isin(airports)]\n",
        "fdf = fdf.astype({\"DepTime\":np.int64,\"ArrTime\":np.int64,\"DepDelayMinutes\":np.int64,\"ArrDelayMinutes\":np.int64,\"DepDel15\":np.int64,\"ArrDel15\":np.int64})\n",
        "fdf = fdf.reset_index(drop=True)\n",
        "fdf[\"H_dept\"] =  pd.Series([hour(x)-100 for x in fdf[\"DepTime\"]])\n",
        "fdf[\"H_arr\"] = pd.Series([hour(x)-100 for x in fdf[\"ArrTime\"]])\n",
        "\n",
        "fdf.shape\n",
        "x = list(set(fdf[\"H_dept\"]))\n",
        "x.sort()\n",
        "print(x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qojx-Ct3YkU7"
      },
      "source": [
        "def JTD(fpth,airport,year,month):\n",
        "\n",
        "  wlist = []\n",
        "  with open(fpth) as json_file:\n",
        "    wdic = json.load(json_file)[\"data\"][\"weather\"]\n",
        "  \n",
        "  for day in days:\n",
        "    for hour in hours:\n",
        "      tlist = [airport,year,month,day+1,hour]\n",
        "      for key in weatherKeys:\n",
        "        try :\n",
        "          tlist.append(wdic[day][\"hourly\"][hour][key]) \n",
        "        except:\n",
        "          pass\n",
        "      if len(tlist) ==18:\n",
        "        wlist.append(tlist)\n",
        "  return pd.DataFrame(wlist,columns=weatherCols)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okTtiUAUV14A"
      },
      "source": [
        "import json \n",
        "pth= \"drive/MyDrive/Data/weather\"\n",
        "# count = 0\n",
        "wtlist = [ ]\n",
        "for airport in airports:\n",
        "  for year in years:\n",
        "    for month in months:\n",
        "      fpth = os.path.join(pth,airport,str(year)+\"-\"+str(month)+\".json\")\n",
        "      wtlist.append(delayed(JTD)(fpth,airport,year,month).compute())\n",
        "weatherDF = pd.concat(wtlist,ignore_index=True)\n",
        "weatherDF = weatherDF.astype({\"Year\":np.int64,\"Time\":np.int64})\n",
        "\n",
        "weatherDF.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ds2iNR6lX88"
      },
      "source": [
        "lst1 = [\"Year\",\"Month\",\"DayofMonth\",\"H_dept\",\"Origin\"]\n",
        "lst2 = [\"Year\",\"Month\",\"DayofMonth\",\"H_arr\",\"Dest\"]\n",
        "lst3 = [\"Year\",\"Month\",\"Day\",\"Time\",\"Airport\"]\n",
        "\n",
        "InfoDF = fdf.merge(weatherDF, left_on=lst1, right_on=lst3)\n",
        "print(InfoDF.shape)\n",
        "InfoDF = InfoDF.merge(weatherDF, left_on=lst2, right_on=lst3, suffixes=(\"$Origin$\", \"$Dest$\"))\n",
        "InfoDF.shape\n",
        "InfoDF.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7vuZR0rJTZJ"
      },
      "source": [
        "InfoDF.to_csv(\"drive/MyDrive/Data/Info.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooP9jI4xqcMr"
      },
      "source": [
        "* Dask\n",
        "* isin function\n",
        "* how to see list of names in coloum : print(df.columns.tolist())\n",
        "* how to select list of coloums in pandas : df = pd.read_csv('data.csv', skipinitialspace=True, usecols=fields)\n",
        "* dropna to drop coloumn with no values \n",
        "* shift + home = all text till begin\n",
        "* shift + end = vice versa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63wd2rX2gCS"
      },
      "source": [
        "\n",
        "WindSpeedKmph\tWindDirDegree\tWeatherCode\tprecipMM\tVisibility\tPressure\tCloudcover\tDewPointF\tWindGustKmph\ttempF\tWindChillF\tHumidity\tTime\n",
        "0\t11\t318\t176\t0.1\t10\t1023\t100\t47\t17\t49\t46\t91\t0\n",
        "1\t13\t317\t176\t0.0\t10\t1023\t100\t44\t22\t46\t42\t92\t100\n",
        "2\t14\t315\t122\t0.0\t10\t1023\t100\t41\t26\t43\t38\t92\t200\n",
        "3\t16\t314\t122\t0.0\t10\t1023\t100\t38\t30\t40\t33\t93\t300\n",
        "4\t17\t314\t122\t0.0\t10\t1023\t100\t38\t30\t40\t33\t93\t400\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "739\t13\t169\t122\t0.0\t10\t1015\t96\t54\t20\t60\t60\t82\t1900\n",
        "740\t13\t165\t122\t0.0\t10\t1015\t95\t54\t20\t60\t59\t82\t2000\n",
        "741\t12\t162\t122\t0.0\t10\t1015\t95\t54\t20\t59\t59\t83\t2100\n",
        "742\t13\t164\t122\t0.0\t10\t1015\t92\t54\t21\t59\t58\t83\t2200\n",
        "743\t14\t167\t122\t0.0\t10\t1015\t89\t53\t23\t58\t57\t84\t2300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugBobSDQdssq"
      },
      "source": [
        "# New section"
      ]
    }
  ]
}
